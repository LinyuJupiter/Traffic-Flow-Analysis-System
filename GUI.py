import tkinter as tk
from tkinter import filedialog
from PIL import Image, ImageTk
from ultralytics import YOLO
import cv2
import os
import numpy as np
from tkinter import messagebox
import threading
from tkinter import ttk  # ttkåŒ…å«äº†ä¸€äº›æ›´ç°ä»£çš„widgetï¼Œå¦‚Combobox
import time

root = tk.Tk()
root.geometry("1000x600")
root.resizable(False, False)

# åˆ›å»ºä¸¤ä¸ªStringVarå¯¹è±¡æ¥åˆ†åˆ«å­˜å‚¨å›¾åƒå’Œè§†é¢‘çš„æ–‡ä»¶è·¯å¾„
file_path_var_image = tk.StringVar()
file_path_var_video = tk.StringVar()

# åˆ›å»ºä¸€ä¸ªç”¨äºæ˜¾ç¤ºå›¾ç‰‡çš„Canvas
# åˆšå¼€å§‹æˆ‘ç”¨çš„æ˜¯labelæ¥æ˜¾ç¤ºï¼Œåæ¥å‘ç°é€‰ä¸­å›¾ç‰‡æˆ–è§†é¢‘åä¼šæ”¹å˜å¤§å°æ¥é€‚åº”å›¾ç‰‡
# ä»è€Œæ”¹å˜äº†æ•´ä¸ªçª—å£çš„å¸ƒå±€ï¼Œæ‰€ä»¥ä½¿ç”¨Canvasæ¥æ˜¾ç¤ºå›¾ç‰‡
canvas = tk.Canvas(root, width=800, height=450, bg='white', highlightbackground="yellow", highlightthickness=2)
canvas.place(x=5, y=130)

runnin = False


# æ‰“å¼€å›¾ç‰‡
def open_image_file():
    global running
    running = False
    file_path = filedialog.askopenfilename(filetypes=[("Image files", "*.jpg *.jpeg *.png")])
    file_path_var_image.set(file_path)
    file_path_var_video.set('')  # æ¸…ç©ºè§†é¢‘æ–‡ä»¶è·¯å¾„æ˜¾ç¤º
    # ç”¨PILåº“æ‰“å¼€å›¾åƒå¹¶æ˜¾ç¤ºåœ¨Canvasä¸Š
    image = Image.open(file_path)
    image.thumbnail((800, 600))  # æŠŠå›¾åƒç¼©æ”¾åˆ°åˆé€‚çš„å¤§å°ä»¥é€‚åº”canvas
    photo = ImageTk.PhotoImage(image)
    canvas.create_image(0, 0, anchor='nw', image=photo)
    canvas.image = photo  # ä¿å­˜å¯¹PhotoImageå¯¹è±¡çš„å¼•ç”¨ï¼Œé˜²æ­¢è¢«åƒåœ¾å›æ”¶

    text1.configure(state='normal')
    text1.delete(1.0, 'end')
    text1.insert(1.0, file_path_var_image.get())
    text1.configure(state='disabled')
    # åœ¨é€‰ä¸­å›¾ç‰‡åï¼Œè¦æŠŠé€‰ä¸­è§†é¢‘çš„è·¯å¾„æ¸…é™¤
    text2.configure(state='normal')  # å…è®¸ä¿®æ”¹æ–‡æœ¬æ¡†å†…å®¹
    text2.delete(1.0, 'end')  # æ¸…é™¤æ–‡æœ¬æ¡†å†…å®¹
    text2.configure(state='disabled')  # è®¾ç½®ä¸ºåªè¯»æ¨¡å¼


# åˆå§‹åŒ–è½¦è¾†è®¡æ•°å™¨
vehicle_count = 0
vehicle_up = 0
vehicle_down = 0
# åˆ›å»ºä¸€ä¸ªç©ºçš„å­—å…¸ï¼Œç”¨äºè·Ÿè¸ªæ¯è¾†è½¦çš„è¿›å…¥å’Œç¦»å¼€
vehicles = {}


# æ‰“å¼€è§†é¢‘
def open_video_file():
    global running
    running = False
    file_path = filedialog.askopenfilename(filetypes=[("Video files", "*.avi *.mp4")])
    file_path_var_video.set(file_path)
    file_path_var_image.set('')  # æ¸…ç©ºå›¾åƒæ–‡ä»¶è·¯å¾„æ˜¾ç¤º
    # é€‰æ‹©è§†é¢‘ç¬¬ä¸€å¸§ä½œä¸ºè¾“å…¥å›¾åƒ
    cap = cv2.VideoCapture(file_path)
    ret, frame = cap.read()
    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    image = Image.fromarray(frame)

    image.thumbnail((800, 600))  # æŠŠå›¾åƒç¼©æ”¾åˆ°åˆé€‚çš„å¤§å°ä»¥é€‚åº”canvas
    photo = ImageTk.PhotoImage(image)
    canvas.create_image(0, 0, anchor='nw', image=photo)
    canvas.image = photo  # ä¿å­˜å¯¹PhotoImageå¯¹è±¡çš„å¼•ç”¨ï¼Œé˜²æ­¢è¢«åƒåœ¾å›æ”¶
    cap.release()

    text2.configure(state='normal')
    text2.delete(1.0, 'end')
    text2.insert(1.0, file_path_var_video.get())
    text2.configure(state='disabled')

    # åœ¨é€‰ä¸­è§†é¢‘åï¼Œè¦æŠŠé€‰ä¸­å›¾ç‰‡è·¯å¾„æ¸…é™¤
    text1.configure(state='normal')  # å…è®¸ä¿®æ”¹æ–‡æœ¬æ¡†å†…å®¹
    text1.delete(1.0, 'end')  # æ¸…é™¤æ–‡æœ¬æ¡†å†…å®¹
    text1.configure(state='disabled')  # è®¾ç½®ä¸ºåªè¯»æ¨¡å¼


root.title("è½¦è¾†æ£€æµ‹ç³»ç»Ÿ")

# åœ¨çª—å£çš„æœ€ä¸Šæ–¹æ·»åŠ ä¸€ä¸ªæ ‡é¢˜
title = tk.Label(root, text="è½¦è¾†æ£€æµ‹ç³»ç»Ÿ", font=("Arial", 24, "bold"))
# title.grid(row=0, column=0, columnspan=2)  # è·¨è¶Šä¸¤åˆ—
title.place(x=300, y=5)

button1 = tk.Button(root, text="æ‰“å¼€å›¾ç‰‡ğŸ“¸", command=open_image_file, bg='blue', fg='white', borderwidth=2,
                    relief='raised')
button1.place(x=35, y=45)

text1 = tk.Text(root, height=1, width=55, bg='light gray', font=('Arial', 12))
text1.place(x=110, y=50)

button2 = tk.Button(root, text="æ‰“å¼€è§†é¢‘ğŸ“¹", command=open_video_file, bg='green', fg='white', borderwidth=2,
                    relief='raised')
button2.place(x=35, y=80)

text2 = tk.Text(root, height=1, width=55, bg='light gray', font=('Arial', 12))
text2.place(x=110, y=90)

# Load the YOLOv8 model
model = YOLO('./car_clp_1.pt')


def detect(img_cv):
    # è¿™é‡Œæ˜¯ç”¨æ¥æ£€æµ‹å›¾åƒçš„ä»£ç 
    results = model(img_cv)  # è¿›è¡Œè¯†åˆ«
    result = results[0]
    # print(result.boxes)
    # print(result.probs)
    img_with_boxes = result.plot(conf=True, boxes=True, labels=True)  # ç”»æ¡†æ¡†
    img_with_boxes_rgb = cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB)  # æ”¹æ ¼å¼

    detection = [
        {
            "class": result.names[int(c)],
            "bounding_box": box,
            "confidence": conf
        }
        for c, box, conf in zip(result.boxes.cls, result.boxes.xyxy, result.boxes.conf)
    ]

    return img_with_boxes_rgb, detection


def detect_image(image_path):
    # é¦–å…ˆæ£€æŸ¥ä¼ å…¥çš„å‚æ•°æ˜¯å¦ä¸ºå­—ç¬¦ä¸²ç±»å‹
    if isinstance(image_path, str):
        img_cv = cv2.imread(image_path)  # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œé‚£ä¹ˆå°±è®¤ä¸ºè¿™æ˜¯ä¸€ä¸ªæ–‡ä»¶è·¯å¾„ï¼Œä½¿ç”¨cv2.imread()è¯»å–å›¾ç‰‡
    else:
        # å¦‚æœä¸æ˜¯å­—ç¬¦ä¸²ï¼Œé‚£ä¹ˆå°±è®¤ä¸ºè¿™æ˜¯ä¸€ä¸ªPIL Imageå¯¹è±¡ï¼Œä½¿ç”¨numpy.array()å°†å…¶è½¬æ¢ä¸ºnumpyæ•°ç»„
        # ç„¶åå°†é¢œè‰²ç©ºé—´ä»RGBè½¬æ¢ä¸ºBGRï¼Œå› ä¸ºOpenCVçš„é¢œè‰²ç©ºé—´æ˜¯BGRï¼Œè€ŒPIL Imageçš„é¢œè‰²ç©ºé—´æ˜¯RGB
        img_cv = cv2.cvtColor(np.array(image_path), cv2.COLOR_RGB2BGR)

    img_with_boxes_rgb, detection = detect(img_cv)

    img_with_boxes_pil = Image.fromarray(img_with_boxes_rgb)  # æ”¹æˆPILå›¾ç‰‡ï¼Œå› ä¸ºè¦åœ¨GUIä¸­æ˜¾ç¤º

    # return img_with_boxes_pil, detection
    return img_with_boxes_pil, detection  # okï¼Œç°åœ¨è¿”å›


def detect_video(video_path):
    global vehicle_count, vehicle_up, vehicle_down, vehicles
    vehicle_count = 0
    vehicle_up = 0
    vehicle_down = 0
    vehicles = {}

    # æ‰“å¼€è§†é¢‘æ–‡ä»¶
    cap = cv2.VideoCapture(video_path)
    # è·å–è§†é¢‘çš„å¸§ç‡å’Œå°ºå¯¸
    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    # åˆ›å»ºä¸€ä¸ªVideoWriterå¯¹è±¡
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter('output.mp4', fourcc, fps, (width, height))
    global running
    running = True  # åŠ è¿™ä¸ªrunningæ˜¯ä¸ºäº†èƒ½å¤Ÿçœ‹è§†é¢‘çœ‹ä¸€åŠé€‰æ‹©æ–°çš„å›¾ç‰‡æˆ–è§†é¢‘æ—¶èƒ½å¤Ÿæš‚åœ

    global playing

    parameters_updated = False
    # while running:
    while cap.isOpened():
        while running:
            if playing:

                # è¯»å–ä¸‹ä¸€å¸§
                ret, frame = cap.read()
                if not ret:
                    break  # å¦‚æœæ²¡æœ‰æ›´å¤šçš„å¸§ï¼Œå°±é€€å‡ºå¾ªç¯

                # å¯¹å¸§åº”ç”¨è½¦è¾†æ£€æµ‹
                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                pil_img = Image.fromarray(frame)
                detected_img, detection = detect(pil_img)
                frame = cv2.cvtColor(np.array(detected_img), cv2.COLOR_RGB2BGR)

                # æ£€æµ‹è½¦è¾†è®¡æ•°
                # Run YOLOv8 inference on the frame
                results = model.track(frame, persist=True)

                # è·å–æ£€æµ‹åˆ°çš„è½¦è¾†è¾¹ç•Œæ¡†
                bboxes = results[0].boxes

                # éå†æ¯ä¸ªè¾¹ç•Œæ¡†
                for bbox in bboxes:
                    # æå–è¾¹ç•Œæ¡†çš„åæ ‡
                    x1, y1, x2, y2 = bbox.xyxy.tolist()[0]
                    position = [(x2 + x1) / 2, (y2 + y1) / 2]
                    # æ„é€ è½¦è¾†ID
                    vehicle_id = str(bbox.id)

                    # å¦‚æœæ˜¯æ–°çš„è½¦è¾†
                    if vehicle_id not in vehicles:
                        # æ·»åŠ è½¦è¾†åˆ°å­—å…¸ä¸­
                        vehicles[vehicle_id] = {"position": position}
                    if position[1] >= frame.shape[0] // 2 >= vehicles[vehicle_id]["position"][1]:
                        vehicle_down += 1
                        vehicle_count += 1
                        vehicles[vehicle_id]["position"] = position
                    elif position[1] <= frame.shape[0] // 2 <= vehicles[vehicle_id]["position"][1]:
                        vehicle_up += 1
                        vehicle_count += 1
                        vehicles[vehicle_id]["position"] = position
                    else:
                        pass

                annotated_frame = results[0].plot()
                annotated_frame[int(frame.shape[0] // 2), :, :] = 0  # æ·»åŠ è¯†åˆ«çº¿
                cv2.putText(annotated_frame, "vehicle_count:" + str(vehicle_count), (30, 40), cv2.FONT_HERSHEY_SIMPLEX,
                            1.5,
                            (255, 0, 0), 2)
                cv2.putText(annotated_frame, "vehicle_up:" + str(vehicle_up), (30, 80), cv2.FONT_HERSHEY_SIMPLEX, 1.5,
                            (255, 0, 0), 2)
                cv2.putText(annotated_frame, "vehicle_down:" + str(vehicle_down), (30, 120), cv2.FONT_HERSHEY_SIMPLEX,
                            1.5,
                            (255, 0, 0), 2)

                # Convert the image from BGR color (which OpenCV uses) to RGB color
                img = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)

                # Convert the Image object into a TkPhoto object
                im = Image.fromarray(img)
                im.thumbnail((800, 600))  # ç¼©æ”¾å›¾åƒä»¥é€‚åº”canvas
                imgtk = ImageTk.PhotoImage(image=im)

                # Clear previous items on the canvas
                canvas.delete('all')

                # Put the image on the canvas by creating an image object, and then drawing it
                canvas.create_image(0, 0, anchor='nw', image=imgtk)
                canvas.image = imgtk  # ä¿å­˜å¯¹PhotoImageå¯¹è±¡çš„å¼•ç”¨ï¼Œé˜²æ­¢è¢«åƒåœ¾å›æ”¶

                # Add center line
                canvas.create_line(0, frame.shape[0] // 2, frame.shape[1], frame.shape[0] // 2, fill='red')

                # Add texts
                canvas.create_text(30, 40, fill="blue", font="Times 20 italic bold",
                                   text="Vehicle count: " + str(vehicle_count))
                canvas.create_text(30, 80, fill="blue", font="Times 20 italic bold",
                                   text="Vehicle up: " + str(vehicle_up))
                canvas.create_text(30, 120, fill="blue", font="Times 20 italic bold",
                                   text="Vehicle down: " + str(vehicle_down))

                # Put the image on   the canvas by creating an image object, and then drawing it
                canvas.create_image(0, 0, anchor='nw', image=imgtk)
                canvas.image = imgtk  # ä¿å­˜å¯¹PhotoImageå¯¹è±¡çš„å¼•ç”¨ï¼Œé˜²æ­¢è¢«åƒåœ¾å›æ”¶

                # æŠŠæ£€æµ‹åˆ°çš„è½¦è¾†æ ‡æ³¨å‡ºæ¥ï¼Œå¹¶å†™å…¥æ–°çš„å¸§
                out.write(frame)

                # åœ¨è§†é¢‘æ’­æ”¾æ—¶é‡ç½®å˜é‡
                parameters_updated = False

                # ç­‰å¾…GUIæ›´æ–°
                root.update_idletasks()
                root.update()
            else:
                # åªæœ‰åœ¨å‚æ•°è¿˜æ²¡æœ‰è¢«æ›´æ–°æ—¶æ‰æ›´æ–°å®ƒä»¬
                if not parameters_updated:
                    update_right_part(detection)
                    parameters_updated = True
                time.sleep(0.1)

    # å…³é—­è§†é¢‘æ–‡ä»¶
    # cap.release()
    out.release()


playing = True


def play_pause():  # æŠ“æ‹åŠŸèƒ½ï¼Œç›¸å½“äºæš‚åœ
    global playing
    playing = not playing
    button4.config(text="æŠ“æ‹" if playing else "ç»§ç»­")


button4 = tk.Button(root, text="æŠ“æ‹/ç»§ç»­", command=play_pause, font=("Arial", 14), bg="darkblue", fg="white")
button4.place(x=850, y=450)

right_frame = tk.Frame(root, width=300, height=350)
right_frame.place(x=810, y=50)

label_num_objects = tk.Label(right_frame, text="æ£€æµ‹å¯¹è±¡æ•°é‡:", font=("Arial", 10), bg="white", fg="black")
label_num_objects.place(x=10, y=0)
text_num_objects = tk.Text(right_frame, height=1, width=5)
text_num_objects.place(x=103, y=3)

# åˆ›å»ºä¸€ä¸ªComboboxæ¥å±•ç¤ºæ‰€æœ‰æ£€æµ‹åˆ°çš„å¯¹è±¡

label_select = tk.Label(right_frame, text="åœ¨æ£€æµ‹åé€‰æ‹©å¯¹è±¡è¿›è¡ŒæŸ¥çœ‹ï¼š", font=("Arial", 10), bg="white", fg="black")
label_select.place(x=10, y=40)
combo_var = tk.StringVar()
combo = ttk.Combobox(right_frame, textvariable=combo_var, width=20)
combo.place(x=10, y=63)

# åˆ›å»ºä¸€ä¸ªTextæ§ä»¶æ¥å±•ç¤ºæ‰€é€‰å¯¹è±¡çš„è¯¦ç»†ä¿¡æ¯
label_box = tk.Label(right_frame, text="BOX:", font=("Arial", 10), bg="white", fg="black")
label_box.place(x=10, y=100)
text_box = tk.Text(right_frame, height=10, width=23)
text_box.place(x=10, y=120)

label_class = tk.Label(right_frame, text="class:", font=("Arial", 10), bg="white", fg="black")
label_class.place(x=10, y=260)
text_class = tk.Text(right_frame, height=1, width=10)
text_class.place(x=53, y=263)

label_confidence = tk.Label(right_frame, text="confidence:", font=("Arial", 10), bg="white", fg="black")
label_confidence.place(x=10, y=290)

text_conf = tk.Text(right_frame, height=1, width=10)
text_conf.place(x=83, y=293)


# ç”¨äºæ›´æ–°å³è¾¹æ§ä»¶çš„å‡½æ•°
def update_right_part(detection):
    # æ¸…ç©ºComboboxå’ŒTextæ§ä»¶
    combo['values'] = ()
    text_num_objects.delete(1.0, tk.END)
    text_box.delete(1.0, tk.END)
    text_class.delete(1.0, tk.END)
    text_conf.delete(1.0, tk.END)

    # ç”¨æ‰€æœ‰æ£€æµ‹åˆ°çš„å¯¹è±¡æ›´æ–°Combobox
    combo['values'] = [f'Object {i + 1}' for i in range(len(detection))]
    # æ›´æ–°æ£€æµ‹åˆ°çš„å¯¹è±¡çš„æ•°é‡
    text_num_objects.insert(tk.END, str(len(detection)))

    # åˆ›å»ºä¸€ä¸ªå‡½æ•°æ¥å¤„ç†å½“Comboboxçš„é€‰é¡¹æ”¹å˜æ—¶çš„äº‹ä»¶
    def on_combo_changed(event):
        # è·å–å½“å‰é€‰ä¸­çš„å¯¹è±¡çš„ç´¢å¼•
        index = combo.current()
        if index >= 0:  # å¦‚æœæœ‰å¯¹è±¡è¢«é€‰ä¸­
            detect = detection[index]
            # æ¸…ç©ºå¹¶æ›´æ–°Textæ§ä»¶çš„å†…å®¹
            text_box.delete(1.0, tk.END)
            # print(str(detection["bounding_box"]))
            x1 = detection[index]["bounding_box"][0].item()
            y1 = detection[index]["bounding_box"][1].item()
            x2 = detection[index]["bounding_box"][2].item()
            y2 = detection[index]["bounding_box"][3].item()
            txt = 'x1: ' + str(x1) + '\n' + '\n' + 'y1: ' + str(y1) + '\n' + '\n' + 'x2: ' + str(
                x2) + '\n' + '\n' + 'y2: ' + str(y2) + '\n'

            text_box.insert(tk.END, txt)
            text_class.delete(1.0, tk.END)
            text_class.insert(tk.END, detect["class"])
            text_conf.delete(1.0, tk.END)
            text_conf.insert(tk.END, detect["confidence"].item())

    # ç»‘å®šè¿™ä¸ªå‡½æ•°åˆ°Comboboxçš„<<ComboboxSelected>>äº‹ä»¶ä¸Š
    combo.bind('<<ComboboxSelected>>', on_combo_changed)


def start_detection():
    global playing

    # è·å–å›¾åƒå’Œè§†é¢‘æ–‡ä»¶è·¯å¾„
    image_path = file_path_var_image.get()
    video_path = file_path_var_video.get()
    # æ ¹æ®æ–‡ä»¶ç±»å‹è°ƒç”¨ä¸åŒçš„å¤„ç†ä»£ç 
    if image_path:  # å¦‚æœæœ‰å›¾åƒæ–‡ä»¶è·¯å¾„

        playing = False
        extension = os.path.splitext(image_path)[1].lower()
        if extension in ['.jpg', '.jpeg', '.png']:
            # è°ƒç”¨ä½ çš„è½¦è¾†æ£€æµ‹ä»£ç 
            image, detection = detect_image(image_path)

            # å¹¶å°†ç»“æœæ˜¾ç¤ºåˆ°canvasä¸­
            image.thumbnail((800, 600))  # æŠŠå›¾åƒç¼©æ”¾åˆ°åˆé€‚çš„å¤§å°ä»¥é€‚åº”canvas
            photo = ImageTk.PhotoImage(image)
            canvas.create_image(0, 0, anchor='nw', image=photo)
            canvas.image = photo  # ä¿å­˜å¯¹PhotoImageå¯¹è±¡çš„å¼•ç”¨ï¼Œé˜²æ­¢è¢«åƒåœ¾å›æ”¶

            # æ›´æ–°å³è¾¹çš„
            update_right_part(detection)
            pass
    elif video_path:  # å¦‚æœæœ‰è§†é¢‘æ–‡ä»¶è·¯å¾„
        playing = True
        extension = os.path.splitext(video_path)[1].lower()
        if extension in ['.avi', '.mp4']:
            # åœ¨æ–°çš„çº¿ç¨‹ä¸­å¯åŠ¨è§†é¢‘å¤„ç†ï¼Œé˜²æ­¢ç•Œé¢é˜»å¡
            thread = threading.Thread(target=detect_video, args=(video_path,))
            thread.start()
    pass


button3 = tk.Button(root, text="å¼€å§‹æ£€æµ‹ï¼", command=start_detection, bg="red", fg="white", font=("Arial", 18, "bold"),
                    relief="raised", borderwidth=5)
button3.place(x=620, y=50)

root.mainloop()
